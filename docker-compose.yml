version: "3.9"
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - kafka-net

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - mysql
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    restart: on-failure
    ports:
      - '9092:9092'
    networks:
      - kafka-net

  scraper:
    build:
      context: ./scraper
      dockerfile: Dockerfile.scraper
    command: ["scrapy", "crawl", "myfancycrawler", "-s", "LOG_LEVEL=INFO", "--nolog", "-s", "JOBDIR=crawls/state"]
#    depends_on:
#      - kafka
    networks:
      - kafka-net
#
  db_service:
    build:
      context: ./db_service
      dockerfile: Dockerfile.consumer
    command: sh -c "uvicorn src.endpoints:app --host 0.0.0.0 --port 8000"
    #żeby uzbierać dane do bazy odkomentować command poniżej a zakomentować tenz gory, ten z góry odpala fastapi, nie wiem jak odpalić je jednocześnie bo && nie działa
    # command: sh -c "python /src/db_listener.py"
    # depends_on:
    #   - kafka
    #   - mysql
    ports:
      - 8000:8000
    networks:
      - kafka-net

  mysql:
    build:
      context: ./mysql
      dockerfile: Dockerfile.mysql
    image: mysql:latest
    restart: always
    environment:
       MYSQL_DATABASE: 'offers'
       MYSQL_ROOT_PASSWORD: 'root'
    ports:
       - '3306:3306'
    networks:
       - kafka-net

networks:
  kafka-net:
    driver: bridge